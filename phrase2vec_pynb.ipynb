{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSoUzIeRB80g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f46622-a1e0-4209-d7c5-a03b1f39fb2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.4)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.9.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "2022-09-01 10:31:54.323243: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rake-nltk\n",
            "  Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /usr/local/lib/python3.7/dist-packages (from rake-nltk) (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.64.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (2022.6.2)\n",
            "Installing collected packages: rake-nltk\n",
            "Successfully installed rake-nltk-1.0.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yake\n",
            "  Downloading yake-0.4.8-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from yake) (1.21.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from yake) (0.8.10)\n",
            "Collecting segtok\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from yake) (2.6.3)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.7/dist-packages (from yake) (7.1.2)\n",
            "Collecting jellyfish\n",
            "  Downloading jellyfish-0.9.0.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 11.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from segtok->yake) (2022.6.2)\n",
            "Building wheels for collected packages: jellyfish\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.9.0-cp37-cp37m-linux_x86_64.whl size=74021 sha256=8a28d6310700075b8a1cbbd1cdf99ef10373b2eea259719db3b5e90312b9f703\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/99/4e/646ce766df0d070b0ef04db27aa11543e2767fda3075aec31b\n",
            "Successfully built jellyfish\n",
            "Installing collected packages: segtok, jellyfish, yake\n",
            "Successfully installed jellyfish-0.9.0 segtok-1.5.11 yake-0.4.8\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install rake-nltk\n",
        "!pip install nltk\n",
        "!pip install gensim\n",
        "!pip install yake"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "spacy_obj = spacy.load('en_core_web_sm')\n",
        "\n",
        "fil=open(\"/sample.txt\",'r')\n",
        "\n",
        "text=fil.read()\n",
        "\n",
        "print(text)\n"
      ],
      "metadata": {
        "id": "-6MsK2XFCVpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "162c1313-5e4c-4ff7-d4e5-9b96e12f4320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating The Myth of Average through Evidences\n",
            "Most formal educational practices based on the classroom, imparts skills and knowledge at scale, by adopting the model of a factory. Here, the focus is on creation of formal processes, mass production of measurable outcomes, and standardization. Curricula and educational practices are designed for a hypothetical ``average\" student, having ``average\" abilities. However, recent advances in individualization have found vast discrepancies between  individual traits and group averages. Designing models based on group averages, are usually ineffective when the individual is the target beneficiary. This research proposes Evidence Based Competency Model as a mechanism for providing individualized learning experiences. Here, the term evidence, refers to informal data generated by the learner, pertinent to the learning process. Individual models are built for each learner, based on their learning activities. These models are clustered to observe  similarity in learning patterns among the individual learners. This study also shows significant variability from the ``average model\", validating The Myth of Average. \n",
            "Keywords:\n",
            "Evidence, Average Model, Individualization, Evidence Based Competency Model, Learning Process.\n",
            "Introduction:\n",
            "\n",
            "The objective of education is to create empowered individuals that are capable of problem solving, upholding their individuality, and possessing an ability to acquire relevant competencies in their area of interests. Standardization of learning practices based on the classroom, has lead to uniform teaching and assessment practices without regard to how disparate individuals behave, learn, develop and apply their knowledge. \n",
            "\n",
            "The classroom model is able to provide pedagogical solutions at scale by addressing the needs of a hypothetical ``average'' individual. However, research on individualization have shown that, as the number of dimensions of concern increase, the probability of finding an individual who is average on all dimensions rapidly diminishes to zero. This is popularly called The Myth of the Average.  A uniform model based on statistical averages does not capture the patterns of variability among individual learners.  Each individual has different interests, disposition, contexts and styles to learn different topics.\n",
            "\n",
            "One of the emerging approaches towards standardizing pedagogy models, is to focus on learning outcomes. The Outcome Based Education (OBE) model focuses on learner's ability to produce specific, measurable outcomes as part of the learning process. The emphasis on visible outcomes, discounts the holistic nature of education comprising of a number of tacit elements and OBE is also considered to be strongly rooted in behaviorist learning practices, that are incompatible with other learning cultures like constructivist  education.\n",
            "\n",
            "In this work, we show that data generated during the learning process, referred to as evidence, can be used to reason about the underlying competency. We also show that one single average model to predict the state of the competency cannot be used and we need to build separate models for learners, hence validating the Myth of Average, discussed in more detail,  in.\n",
            "\n",
            "The use of activity data, rather than assessments and outcomes, for determining learner's latent competency levels, have been addressed for specific activities in. The focus here has been to correlate different types of learning activities like watching video or learning by doing activities, to their implication on learning. \n",
            "\n",
            "In this work, we don't focus on any specific learning activity and follow a generic approach to collect any kind of learning data and use machine learning techniques to correlate characteristics of activity data with data from outcomes and formal assessments. We focus on activities involving learners consuming resources like videos, text books, articles, documents in the current implementation of the model.\n",
            "\n",
            "Evidence Modeling:\n",
            "The term ``evidence'' is contrasted with ``outcomes'' as follows: outcomes refer to assessment data collected from formal testing environments, where the learner is fully cognizant of being assessed and has explicitly prepared for the same. In contrast, evidence pertains to data collected on an implicit, continuous basis on any activity of the learner pertaining to the competency in question.\n",
            "Existing methods of determining the underlying competency of a learner through formal assessments and visible outcomes, has its own issues. \n",
            "There is a need for models that uses evidences, based on the learner's activities and maps these learners to their competencies.\n",
            "\n",
            "We propose a model that explores the activity data of the learners, generated while achieving the competency. The data, collected implicitly in a continuous fashion, is modeled to map the learners to their competencies.\n",
            "\n",
            "Evidences can be considered analogous to an observation that an individual makes, in the classroom through interaction or silent observation of reactions, which contains significant insights. An offline system like a classroom is unable to gather data for each individual during the learning process, but when learning happens in a Technology Assisted Learning Environment(TALE), data is continuously captured by the platform. Technology augmentation can happen in various ways -- like sensors and RFID tags to record attendance, recording and analysis of students' classroom activities like questions, discussions, etc. We want to focus on the evidences, so that we dont have to rely only on the formal assessments to determine the competency of the learner. \n",
            "\n",
            "A competency model based on evidences can also be used to identify anomalous cases where the outcomes state that the individual has the competency while the evidence indicates a lack of competency, or vice-versa. A teacher can only analyze such cases and address them appropriately. The model based on evidences, acts as a way of aiding the teacher in teaching and evaluating process. % It can also help the students identify areas they are weak in, and help them acquire the competency.\n",
            "\n",
            "Newer learning domains like training drivers to learn a particular language that would improve their communication skills, may not have standardized competency models to aid in pedagogy and assessments. In such cases, models based on evidences would help to map the learners to their competencies. \n",
            "\n",
            "The main challenge is to create an evidence model for collecting data, and to argue for the completeness of the evidence. Learning may happen outside of the evidence gathering, and different kinds of learning activities may require different kinds of evidences to reason about them. \n",
            "\n",
            "In order to address the above challenge, we adopt a least-biased model for evidence modeling, and treat each form of evidence as equally important in the input feature vector. All forms of evidences collected are then given as input to a machine learning algorithm to find the best possible indicators for the outcomes based on assessment scores. \n",
            "\n",
            "Experiments and Initial Results:\n",
            "\n",
            "The activity data used to build models is collected from a large, open online learning platform, implemented across several schools in the US. The platform has aggregated open learning resources for various courses, provided by content creators, curators and instructors. The learning resource can be a document, video, audio, puzzles or any content used to obtain the competency. Learners enroll to various courses. \n",
            "\n",
            "A course is organized into several competencies, where a competency is seen as the basic unit of learning. Each competency may have several learning resources mapped to it. Students consume learning resources and whenever they are ready, give assessments to earn a score. Instructors evaluate the assessments and provide their feedback in the form of scores. The scores indicate the status of the learner with respect to the competency. The learning resources are mapped to competencies for various courses like Maths, Science, English and Social Science in the K-12 curriculum.  %Each competency also has a signature assessment that the learner has to take in order to earn a status for that competency. \n",
            "\n",
            "The activity data collected for a (learner, competency) pair, is divided into collections and assessments. Collections are resources used during the learning process, while assessments act as indicators of learning. In the platform, a learner is said to have achieved a ``completed\" status for a competency if one gets more than 80% in the respective assessments. The platform does not award a ``fail\" status to the learner. The learner keeps attempting assessments multiple times until the learner gets 80% or more. The status is then set to ``completed\", else the status is marked as ``in-progress\". %The data used to build Evidence based competency model contains learners who have completed status as well as in-progress status with respect to a particular competency.\n",
            "\n",
            "Whenever a learner consumes a resource to learn a concept, an event is logged in the system with the details of the resource, time of the event, learner details and type of event(started consuming the resource). The same process is repeated when the learner finishes consuming the resource with a stop event. The events are captured for all the courses. Individuals consume various resources mapped to the same competency and at the end give assessments to get a particular status for that competency.  \n",
            "\n",
            "Using these activity data we have built a model to determine the outcome of the competency based on the evidences.\n",
            "\n",
            "Experiment 1: \n",
            "We built a Support Vector Machine (SVM) classifier to test a hypothesis. Our hypothesis is as follows: Ht: The time spent on learning resources, the total number of resources consumed by learners, can predict the outcome for the underlying competency.\n",
            "\n",
            "The features identified are total time spent on resources, average time spent on resources and number of resources used for acquiring the corresponding competency. The users were given a completed or in-progress status based on their assessment scores. That serves as the ground truth for our model. \n",
            "\n",
            "The dataset has 28000 (user,competency) pairs with their corresponding evidences. This data was divided into 80-20 split randomly for training and testing the SVM model respectively. We built a single SVM model for all learners and their competencies in all courses. We classified the data using linear, polynomial, sigmoid and radial basis kernel function. The data was not linearly separable. The radial basis kernel function was found to be the best kernel function to classify the data in terms of Accuracy, Precision and F1 score as shown in Table 1. \n",
            "\n",
            "Kernel functions Accuracy Precision F1 score\n",
            "Radial basis 82.43% 68.79% 51.13%\n",
            "Linear 78.39% 53.65% 40.30%\n",
            "Polynomial 78.83% 56.25% 37.91%\n",
            "Sigmoid 68.84% 30.68% 30.37%\n",
            "\n",
            "Table 1: Performance metrics comparing the kernels\n",
            "\n",
            "The accuracy measure of the SVM model using the radial basis function states that using total time spent, average time spent on the resources and number of resources, we can significantly predict the outcome of the underlying competency. The outcomes are determined by the scores of the assessments, which was not used as feature to build the models. This shows that evidence can be used as an alternate way to model the outcome of the underlying competency. \n",
            "\n",
            "The same model was made to classify all the competencies of a random individual learner, the accuracy of the average SVM model varied between 30% to 100% for different learners . The ``average learner'' model computed above, was not effective in determining the outcome of a competency of an individual learner. This indicates that we cannot use one single aggregated model on all individuals. %There is a need to build individual models to understand the evidences better and improve the way of mapping learners to their competency. \n",
            "Models must consider personalization i.e., we need to build individual models for each users and aggregate the models based on common properties.\n",
            "\n",
            "To do this, we require significant amount of data for each learner. So, instead of aggregating time spent on resources at a competency level as total time, we looked at time spent for each resource and aggregated the data separately for each learner in the next experiment. \n",
            "\n",
            "Experiment 2:\n",
            "In this experiment, we used data from each activity event and modeled the time spent on each resource mapped to a particular competency. Using the start and the stop time, we computed the time spent on each resource and we also observed that some individuals consumed the same resource again. Based on this, we formed our second hypothesis: $H_u$: There is a large variance among the individual models built for each learner based on their learning activity data.\n",
            "\n",
            "We wanted to observe the consumption of resources and the time spent on those resources, could predict the outcome of the corresponding competency for that individual learner. We also wanted to observe if the models built for each individual learner had common properties and could be merged to a single model or there is a large variance among them. \n",
            "\n",
            "The amount of time spent on each resource is stored as a vector for each (learner,competency) pair, the length of the vector is the number of resources and the order of the vector tells the order in which the resources were consumed. The length of the vector varied for each (learner,competency) pair. To build individual learner models and compare them, we require equal number of features for all pairs of (learner, competency). \n",
            "\n",
            "To achieve this we transformed the time spent on resource vector, to a matrix in the following way. We computed the range of total time spent on (resource,competency) pair by all learners. This value varied from 10 seconds to 46000 seconds. After observing this distribution, we decided to have a time frequency of 100 seconds and computed the cumulative sum of resources consumed by the learner at each frequency i.e. 100th second, 200th second etc.  We populated 460 time frequency columns. We arrived at this time frequency value of 100 seconds by dividing the maximum total time and time frequency. \n",
            "\n",
            "For example, if the learner has consumed 2 resources for a competency code ``3'', spending 90 seconds on first resource and 170 seconds on second resource then the column 0(time_100) will have the value 1, column 1(time_200) will have the value 1 as the learner has not finished consuming the second resource by 200 seconds, column 2(time_300) has the value 2 and rest of the columns till column 459(time_460) will have the value 2 indicating that the user consumed maximum 2 resources. Fig.1, shows the subset of the data passed to the model for a single user, where code refers to competency code and rest of the columns are the evidences for that competency code for a single learner. The row containing code value 3, shows the corresponding result of example mentioned above. The features also includes normalized total_time spent on resources and normalized average_time spent on those resources for a particular (competency, learner) pair. \n",
            "\n",
            "Figure 1: Data passed to the classifier with cumulative frequency of resources with respect to time, total time and average time as features.\n",
            "\n",
            "SVM model with linear kernel was used to classify the data. Learners who had more than 30 competencies in any course and with any status (completed or in-progress), were selected for analysis. There were 42 learners who satisfied that criteria and individual SVM models were built for those learners. Individual learner's data was divided into 80-20 split randomly for training and testing respectively. The models for each learner gave an accuracy between 80% to 100%. The accuracy was calculated from the confusion matrix generated for each individual model according to the formula mentioned in. Each model generated a coefficient vector of length 462. We also built a single model comprising the activity data all these 42 learners and called this the ``average-model\", as detailed in Experiment 1, for comparison. \n",
            "\n",
            "All the 43 vectors of coefficients for the 43 models populated were clustered using the K-nearest neighbor clustering algorithm to observe any similarity among these models. The Euclidean distance between the data points (models) was used as a measure to cluster the models. To find the appropriate number of clusters, Elbow method was used to find the optimal number of clusters. The summation of distance between that specific cluster against the cluster centroid was computed and plotted for various number of clusters, between 1 and 43 where 43 was the total number of models.  The graph in Fig. 2 shows the variance in the sum of the squared distance between clusters against the number of clusters.\n",
            "\n",
            "Figure 2: Elbow method showing the variance of number of clusters and their distances\n",
            "\n",
            "Using the variance in the Elbow method, we found the optimal number of clusters to be 6. This says that the 43 models including the average model can be clustered into 6 clusters, and there are some common properties among these models. \n",
            "\n",
            "Fig.3 shows the distribution of 43 different models including the average model into 6 different clusters. The blue point refers to individual learner models and the red point indicates the ``average learner'' model. \n",
            "\n",
            "Figure 3: Distribution of individual learners models and average model into 6 clusters\n",
            "\n",
            "We see that the individual models don't cluster with the average model. For this dataset, the average model does not represent any individual learner. This validates our hypothesis that there is large variance among the individual models built for each learner based on their learning activity data and hence validates ``The Myth of the Average\". It also shows that we need not build one model for each individual which would make it extremely difficult to map new learners to their competencies. We find that there are some common properties among the learners which can be used to find the best model for each learner. We need to determine those common properties in the future and provide better learning experiences to each individual learner.\n",
            "\n",
            "Conclusion:\n",
            "\n",
            "We proposed an Evidence Based Competency Model, that uses data generated during the learning process by learners to find the outcome of the competency. The experiments shows that having a single average model can be tuned to get a higher accuracy, but does not represent any individual. This presses the need to consider individual learner's variance and not rely on statistical averages to map learners to their competencies. This also says that we cannot provide each learner the same learning experience and cannot validate their underlying competencies through uniform evaluation mechanisms like outcomes. This research shows initial results towards that direction.\n",
            "\n",
            "5. ACKNOWLEDGEMENTS\n",
            "The authors would like to acknowledge and thank the con-\n",
            "tributions of the project associates Thrivikram Mudunuri,\n",
            "Juhi Singh, Naman Dosi and Kartik Gupta.\n",
            "6. REFERENCES\n",
            "[1] Todd Rose. The end of average: How to succeed in a\n",
            "world that values sameness . Penguin UK, 2016.\n",
            "[2] L. Todd Rose, Parisa Rouhani, and Kurt W. Fischer.\n",
            "The science of the individual. Mind, Brain, and\n",
            "Education , 7(3), 2013.\n",
            "[3] Maureen Tam. Outcomes-based approach to quality\n",
            "assessment and curriculum improvement in higher\n",
            "education. Quality Assurance in Education ,\n",
            "22(2):158{168, 2014.\n",
            "[4] Laurie Brady. Outcome based education: a critique.\n",
            "The Curriculum Journal , 7(1):5{16, 1996.\n",
            "[5] Praseeda, Srinath Srinivasa, and Prasad Ram.\n",
            "Validating the myth of average through evidence based\n",
            "competency model. Gooru Tech Report , 3(2), 2019.\n",
            "[6] Stephen E. Fancsali, Guoguo Zheng, Yanyan Tan,\n",
            "Steven Ritter, Susan R. Berman, and April Galyardt.\n",
            "Using embedded formative assessment to predict state\n",
            "summative test scores. LAK '18. ACM, 2018.\n",
            "[7] Mingyu Feng, Neil T. Heffernan, and Kenneth R.\n",
            "Koedinger. Predicting state test scores better with\n",
            "intelligent tutoring systems: Developing metrics to\n",
            "measure assistance required. Springer Berlin\n",
            "Heidelberg, 2006.\n",
            "[8] Kenneth R. Koedinger, Jihee Kim, Julianna Zhuxin\n",
            "Jia, Elizabeth A. McLaughlin, and Norman L. Bier.\n",
            "Learning is not a spectator sport: Doing is better than\n",
            "watching for learning from a mooc. L@S '15, pages\n",
            "111{120. ACM, 2015.\n",
            "[9] J.D. Fletcher. Evidence for learning from\n",
            "technology-assisted instruction. Technology\n",
            "Applications in Education: A Learning View , pages\n",
            "79{99, 2003.\n",
            "[10] Corinna Cortes and Vladimir Vapnik. Support-vector\n",
            "networks. In Machine Learning , pages 273{297, 1995.\n",
            "The 12th International Conference on Educational Data Mining\n",
            "634\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_text = spacy_obj(text)\n",
        "for chunk in spacy_text.noun_chunks:\n",
        "  print (chunk)"
      ],
      "metadata": {
        "id": "wRTjTN_pSSn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "860e46fe-fd29-43fe-a972-3bb528d7de0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Myth\n",
            "Average\n",
            "Evidences\n",
            "Most formal educational practices\n",
            "the classroom\n",
            "scale\n",
            "the model\n",
            "a factory\n",
            "the focus\n",
            "creation\n",
            "formal processes\n",
            "mass production\n",
            "measurable outcomes\n",
            "standardization\n",
            "Curricula\n",
            "educational practices\n",
            "a hypothetical ``average\" student\n",
            "``average\" abilities\n",
            "recent advances\n",
            "individualization\n",
            "vast discrepancies\n",
            "individual traits\n",
            "group averages\n",
            "Designing models\n",
            "group averages\n",
            "the individual\n",
            "the target beneficiary\n",
            "This research\n",
            "Evidence Based Competency Model\n",
            "a mechanism\n",
            "individualized learning experiences\n",
            "the term evidence\n",
            "informal data\n",
            "the learner\n",
            "the learning process\n",
            "Individual models\n",
            "each learner\n",
            "their learning activities\n",
            "These models\n",
            "similarity\n",
            "patterns\n",
            "the individual learners\n",
            "This study\n",
            "significant variability\n",
            "the ``average model\n",
            "The Myth\n",
            "Average\n",
            "Evidence\n",
            "Average Model\n",
            "Individualization\n",
            "Evidence Based Competency Model\n",
            "Learning Process\n",
            "Introduction\n",
            "The objective\n",
            "education\n",
            "empowered individuals\n",
            "that\n",
            "problem solving\n",
            "their individuality\n",
            "an ability\n",
            "relevant competencies\n",
            "their area\n",
            "interests\n",
            "Standardization\n",
            "learning practices\n",
            "the classroom\n",
            "uniform teaching and assessment practices\n",
            "regard\n",
            "individuals\n",
            "their knowledge\n",
            "The classroom model\n",
            "pedagogical solutions\n",
            "scale\n",
            "the needs\n",
            "a hypothetical ``average'' individual\n",
            "research\n",
            "individualization\n",
            "the number\n",
            "dimensions\n",
            "concern increase\n",
            "the probability\n",
            "an individual\n",
            "who\n",
            "all dimensions\n",
            "This\n",
            "The Myth\n",
            "the Average\n",
            "A uniform model\n",
            "statistical averages\n",
            "the patterns\n",
            "variability\n",
            "individual learners\n",
            "Each individual\n",
            "different interests\n",
            "disposition\n",
            "contexts\n",
            "styles\n",
            "different topics\n",
            "the emerging approaches\n",
            "pedagogy models\n",
            "outcomes\n",
            "The Outcome Based Education (OBE) model\n",
            "learner's ability\n",
            "specific, measurable outcomes\n",
            "part\n",
            "the learning process\n",
            "The emphasis\n",
            "visible outcomes\n",
            "the holistic nature\n",
            "education comprising\n",
            "a number\n",
            "tacit elements\n",
            "OBE\n",
            "behaviorist learning practices\n",
            "that\n",
            "other learning cultures\n",
            "constructivist  education\n",
            "this work\n",
            "we\n",
            "data\n",
            "the learning process\n",
            "evidence\n",
            "the underlying competency\n",
            "We\n",
            "one single average model\n",
            "the state\n",
            "the competency\n",
            "we\n",
            "separate models\n",
            "learners\n",
            "the Myth\n",
            "Average\n",
            "more detail\n",
            "The use\n",
            "activity data\n",
            "assessments\n",
            "outcomes\n",
            "learner's latent competency levels\n",
            "specific activities\n",
            "The focus\n",
            "different types\n",
            "activities\n",
            "video\n",
            "activities\n",
            "their implication\n",
            "this work\n",
            "we\n",
            "any specific learning activity\n",
            "a generic approach\n",
            "any kind\n",
            "data\n",
            "machine learning techniques\n",
            "characteristics\n",
            "activity data\n",
            "data\n",
            "outcomes\n",
            "formal assessments\n",
            "We\n",
            "activities\n",
            "learners\n",
            "resources\n",
            "videos\n",
            "text books\n",
            "articles\n",
            "documents\n",
            "the current implementation\n",
            "the model\n",
            "Evidence Modeling\n",
            "The term ``evidence\n",
            "``outcomes\n",
            "outcomes\n",
            "assessment data\n",
            "formal testing environments\n",
            "the learner\n",
            "contrast\n",
            "evidence\n",
            "data\n",
            "an implicit, continuous basis\n",
            "any activity\n",
            "the learner\n",
            "the competency\n",
            "question\n",
            "Existing methods\n",
            "the underlying competency\n",
            "a learner\n",
            "formal assessments\n",
            "visible outcomes\n",
            "its own issues\n",
            "a need\n",
            "models\n",
            "that\n",
            "evidences\n",
            "the learner's activities\n",
            "these learners\n",
            "their competencies\n",
            "We\n",
            "a model\n",
            "that\n",
            "the activity data\n",
            "the learners\n",
            "the competency\n",
            "The data\n",
            "a continuous fashion\n",
            "the learners\n",
            "their competencies\n",
            "Evidences\n",
            "an observation\n",
            "an individual\n",
            "the classroom\n",
            "interaction\n",
            "silent observation\n",
            "reactions\n",
            "which\n",
            "significant insights\n",
            "An offline system\n",
            "a classroom\n",
            "data\n",
            "each individual\n",
            "the learning process\n",
            "a Technology Assisted Learning Environment(TALE\n",
            "data\n",
            "the platform\n",
            "Technology augmentation\n",
            "various ways\n",
            "sensors\n",
            "RFID tags\n",
            "record attendance\n",
            "recording\n",
            "analysis\n",
            "students' classroom activities\n",
            "questions\n",
            "discussions\n",
            "We\n",
            "the evidences\n",
            "we\n",
            "the formal assessments\n",
            "the competency\n",
            "the learner\n",
            "A competency model\n",
            "evidences\n",
            "anomalous cases\n",
            "the outcomes\n",
            "the individual\n",
            "the competency\n",
            "the evidence\n",
            "a lack\n",
            "competency\n",
            "vice\n",
            "A teacher\n",
            "such cases\n",
            "them\n",
            "The model\n",
            "evidences\n",
            "a way\n",
            "the teacher\n",
            "teaching and evaluating process\n",
            "It\n",
            "the students\n",
            "areas\n",
            "they\n",
            "them\n",
            "the competency\n",
            "Newer learning domains\n",
            "training\n",
            "drivers\n",
            "a particular language\n",
            "that\n",
            "their communication skills\n",
            "standardized competency models\n",
            "pedagogy\n",
            "assessments\n",
            "such cases\n",
            "models\n",
            "evidences\n",
            "the learners\n",
            "their competencies\n",
            "The main challenge\n",
            "an evidence model\n",
            "data\n",
            "the completeness\n",
            "the evidence\n",
            "Learning\n",
            "the evidence gathering\n",
            "different kinds\n",
            "learning activities\n",
            "different kinds\n",
            "evidences\n",
            "them\n",
            "order\n",
            "the above challenge\n",
            "we\n",
            "a least-biased model\n",
            "evidence modeling\n",
            "each form\n",
            "evidence\n",
            "the input feature vector\n",
            "All forms\n",
            "evidences\n",
            "input\n",
            "a machine\n",
            "algorithm\n",
            "the best possible indicators\n",
            "the outcomes\n",
            "assessment scores\n",
            "Experiments\n",
            "Initial Results\n",
            "The activity data\n",
            "models\n",
            "a large, open online learning platform\n",
            "several schools\n",
            "the US\n",
            "The platform\n",
            "open learning resources\n",
            "various courses\n",
            "content creators\n",
            "curators\n",
            "instructors\n",
            "The learning resource\n",
            "a document\n",
            "video\n",
            "puzzles\n",
            "any content\n",
            "the competency\n",
            "Learners\n",
            "various courses\n",
            "A course\n",
            "several competencies\n",
            "a competency\n",
            "the basic unit\n",
            "Each competency\n",
            "several learning resources\n",
            "it\n",
            "Students\n",
            "resources\n",
            "they\n",
            "assessments\n",
            "a score\n",
            "Instructors\n",
            "the assessments\n",
            "their feedback\n",
            "the form\n",
            "scores\n",
            "The scores\n",
            "the status\n",
            "the learner\n",
            "respect\n",
            "the competency\n",
            "The learning resources\n",
            "competencies\n",
            "various courses\n",
            "Maths\n",
            "Science\n",
            "English\n",
            "Social Science\n",
            "the K-12 curriculum\n",
            "Each competency\n",
            "a signature assessment\n",
            "the learner\n",
            "order\n",
            "a status\n",
            "that competency\n",
            "The activity data\n",
            "a (learner, competency) pair\n",
            "collections\n",
            "assessments\n",
            "Collections\n",
            "resources\n",
            "the learning process\n",
            "assessments\n",
            "indicators\n",
            "the platform\n",
            "a learner\n",
            "a ``completed\" status\n",
            "a competency\n",
            "one\n",
            "more than 80%\n",
            "the respective assessments\n",
            "The platform\n",
            "a ``fail\" status\n",
            "the learner\n",
            "The learner\n",
            "assessments\n",
            "the learner\n",
            "The status\n",
            "the status\n",
            "progress\n",
            "The data\n",
            "Evidence based competency model\n",
            "learners\n",
            "who\n",
            "progress\n",
            "respect\n",
            "a particular competency\n",
            "a learner\n",
            "a resource\n",
            "a concept\n",
            "an event\n",
            "the system\n",
            "the details\n",
            "the resource\n",
            "the event\n",
            "the resource\n",
            "The same process\n",
            "the resource\n",
            "a stop event\n",
            "The events\n",
            "all the courses\n",
            "Individuals\n",
            "various resources\n",
            "the same competency\n",
            "the end\n",
            "assessments\n",
            "a particular status\n",
            "that competency\n",
            "these activity data\n",
            "we\n",
            "a model\n",
            "the outcome\n",
            "the competency\n",
            "the evidences\n",
            "We\n",
            "a Support Vector Machine (SVM) classifier\n",
            "a hypothesis\n",
            "Our hypothesis\n",
            "Ht\n",
            "resources\n",
            "the total number\n",
            "resources\n",
            "learners\n",
            "the outcome\n",
            "the underlying competency\n",
            "The features\n",
            "total time\n",
            "resources\n",
            "resources\n",
            "number\n",
            "resources\n",
            "the corresponding competency\n",
            "The users\n",
            "progress\n",
            "their assessment scores\n",
            "That\n",
            "the ground truth\n",
            "our model\n",
            "The dataset\n",
            "competency\n",
            "their corresponding evidences\n",
            "This data\n",
            "80-20 split\n",
            "training\n",
            "the SVM model\n",
            "We\n",
            "a single SVM model\n",
            "all learners\n",
            "their competencies\n",
            "all courses\n",
            "We\n",
            "the data\n",
            "linear\n",
            "polynomial\n",
            "sigmoid\n",
            "radial basis kernel function\n",
            "The data\n",
            "The radial basis kernel function\n",
            "the best kernel function\n",
            "the data\n",
            "terms\n",
            "Accuracy, Precision and F1 score\n",
            "Table\n",
            "82.43%\n",
            "68.79%\n",
            "51.13%\n",
            "Linear\n",
            "78.39%\n",
            "53.65%\n",
            "40.30%\n",
            "Polynomial 78.83%\n",
            "56.25%\n",
            "37.91%\n",
            "Sigmoid\n",
            "68.84%\n",
            "30.68%\n",
            "30.37%\n",
            "Table\n",
            "Performance metrics\n",
            "the kernels\n",
            "The accuracy measure\n",
            "the SVM model\n",
            "the radial basis function\n",
            "total time\n",
            "the resources\n",
            "number\n",
            "resources\n",
            "we\n",
            "the outcome\n",
            "the underlying competency\n",
            "The outcomes\n",
            "the scores\n",
            "the assessments\n",
            "which\n",
            "feature\n",
            "the models\n",
            "This\n",
            "evidence\n",
            "an alternate way\n",
            "the outcome\n",
            "the underlying competency\n",
            "The same model\n",
            "all the competencies\n",
            "a random individual learner\n",
            "the accuracy\n",
            "the average SVM model\n",
            "different learners\n",
            "The ``average learner'' model\n",
            "the outcome\n",
            "a competency\n",
            "an individual learner\n",
            "This\n",
            "we\n",
            "one single aggregated model\n",
            "all individuals\n",
            "a need\n",
            "individual models\n",
            "the evidences\n",
            "the way\n",
            "mapping learners\n",
            "their competency\n",
            "Models\n",
            "personalization\n",
            "we\n",
            "individual models\n",
            "each users\n",
            "the models\n",
            "common properties\n",
            "this\n",
            "we\n",
            "significant amount\n",
            "data\n",
            "each learner\n",
            "time\n",
            "resources\n",
            "a competency level\n",
            "total time\n",
            "we\n",
            "time\n",
            "each resource\n",
            "the data\n",
            "each learner\n",
            "the next experiment\n",
            "this experiment\n",
            "we\n",
            "data\n",
            "each activity event\n",
            "the time\n",
            "each resource\n",
            "a particular competency\n",
            "the start\n",
            "the stop time\n",
            "we\n",
            "the time\n",
            "each resource\n",
            "we\n",
            "some individuals\n",
            "the same resource\n",
            "this\n",
            "we\n",
            "our second hypothesis\n",
            "$H_u$\n",
            "a large variance\n",
            "the individual models\n",
            "each learner\n",
            "their learning activity data\n",
            "We\n",
            "the consumption\n",
            "resources\n",
            "those resources\n",
            "the outcome\n",
            "the corresponding competency\n",
            "that individual learner\n",
            "We\n",
            "the models\n",
            "each individual learner\n",
            "common properties\n",
            "a single model\n",
            "a large variance\n",
            "them\n",
            "The amount\n",
            "time\n",
            "each resource\n",
            "a vector\n",
            "each (learner,competency) pair\n",
            "the length\n",
            "the vector\n",
            "the number\n",
            "resources\n",
            "the order\n",
            "the vector\n",
            "the order\n",
            "which\n",
            "the resources\n",
            "The length\n",
            "the vector\n",
            "each (learner,competency) pair\n",
            "individual learner models\n",
            "them\n",
            "we\n",
            "equal number\n",
            "features\n",
            "all pairs\n",
            "learner, competency\n",
            "this\n",
            "we\n",
            "the time\n",
            "resource vector\n",
            "a matrix\n",
            "the following way\n",
            "We\n",
            "the range\n",
            "total time\n",
            "resource,competency) pair\n",
            "all learners\n",
            "This value\n",
            "10 seconds\n",
            "46000 seconds\n",
            "this distribution\n",
            "we\n",
            "a time frequency\n",
            "100 seconds\n",
            "the cumulative sum\n",
            "resources\n",
            "the learner\n",
            "each frequency\n",
            "We\n",
            "460 time frequency columns\n",
            "We\n",
            "this time frequency value\n",
            "100 seconds\n",
            "the maximum total time and time frequency\n",
            "example\n",
            "the learner\n",
            "2 resources\n",
            "a competency code\n",
            "90 seconds\n",
            "first resource\n",
            "170 seconds\n",
            "second resource\n",
            "the column 0(time_100\n",
            "the value\n",
            "the value\n",
            "the learner\n",
            "the second resource\n",
            "200 seconds\n",
            "the value\n",
            "rest\n",
            "the columns\n",
            "column 459(time_460\n",
            "the value\n",
            "the user\n",
            "maximum 2 resources\n",
            "Fig.1\n",
            "the subset\n",
            "the data\n",
            "the model\n",
            "a single user\n",
            "code\n",
            "competency code\n",
            "rest\n",
            "the columns\n",
            "the evidences\n",
            "that competency code\n",
            "a single learner\n",
            "The row\n",
            "code value\n",
            "the corresponding result\n",
            "example\n",
            "The features\n",
            "normalized total_time\n",
            "resources\n",
            "normalized average_time\n",
            "those resources\n",
            "a particular (competency, learner) pair\n",
            "Data\n",
            "the classifier\n",
            "cumulative frequency\n",
            "resources\n",
            "respect\n",
            "time\n",
            "features\n",
            "SVM model\n",
            "linear kernel\n",
            "the data\n",
            "Learners\n",
            "who\n",
            "more than 30 competencies\n",
            "any course\n",
            "any status\n",
            "progress\n",
            "analysis\n",
            "42 learners\n",
            "who\n",
            "that criteria\n",
            "individual SVM models\n",
            "those learners\n",
            "Individual learner's data\n",
            "80-20 split\n",
            "training\n",
            "testing\n",
            "The models\n",
            "each learner\n",
            "an accuracy\n",
            "between 80% to 100%\n",
            "The accuracy\n",
            "the confusion matrix\n",
            "each individual model\n",
            "the formula\n",
            "Each model\n",
            "a coefficient vector\n",
            "length\n",
            "We\n",
            "a single model\n",
            "the activity data\n",
            "all these 42 learners\n",
            "this\n",
            "the ``average-model\n",
            "Experiment\n",
            "comparison\n",
            "All the 43 vectors\n",
            "coefficients\n",
            "the 43 models\n",
            "the K-nearest neighbor\n",
            "algorithm\n",
            "any similarity\n",
            "these models\n",
            "The Euclidean distance\n",
            "the data points\n",
            "models\n",
            "a measure\n",
            "the models\n",
            "the appropriate number\n",
            "clusters\n",
            "Elbow method\n",
            "the optimal number\n",
            "clusters\n",
            "The summation\n",
            "distance\n",
            "that specific cluster\n",
            "the cluster centroid\n",
            "various number\n",
            "clusters\n",
            "the total number\n",
            "models\n",
            "The graph\n",
            "Fig\n",
            "the variance\n",
            "the sum\n",
            "the squared distance\n",
            "clusters\n",
            "the number\n",
            "clusters\n",
            "Elbow method\n",
            "the variance\n",
            "number\n",
            "clusters\n",
            "their distances\n",
            "the variance\n",
            "the Elbow method\n",
            "we\n",
            "the optimal number\n",
            "clusters\n",
            "This\n",
            "the 43 models\n",
            "the average model\n",
            "6 clusters\n",
            "some common properties\n",
            "these models\n",
            "Fig.3\n",
            "the distribution\n",
            "43 different models\n",
            "the average model\n",
            "6 different clusters\n",
            "The blue point\n",
            "individual learner models\n",
            "the red point\n",
            "the ``average learner'' model\n",
            "Figure\n",
            "Distribution\n",
            "individual learners models\n",
            "average model\n",
            "6 clusters\n",
            "We\n",
            "the individual models\n",
            "the average model\n",
            "this dataset\n",
            "the average model\n",
            "any individual learner\n",
            "This\n",
            "our hypothesis\n",
            "large variance\n",
            "the individual models\n",
            "each learner\n",
            "their learning activity data\n",
            "The Myth\n",
            "the Average\n",
            "It\n",
            "we\n",
            "one model\n",
            "each individual\n",
            "which\n",
            "it\n",
            "new learners\n",
            "their competencies\n",
            "We\n",
            "some common properties\n",
            "the learners\n",
            "which\n",
            "the best model\n",
            "each learner\n",
            "We\n",
            "those common properties\n",
            "the future\n",
            "better learning experiences\n",
            "each individual learner\n",
            "Conclusion\n",
            "We\n",
            "an Evidence Based Competency Model\n",
            "that\n",
            "data\n",
            "the learning process\n",
            "learners\n",
            "the outcome\n",
            "the competency\n",
            "The experiments\n",
            "a single average model\n",
            "a higher accuracy\n",
            "any individual\n",
            "This\n",
            "the need\n",
            "individual learner's variance\n",
            "statistical averages\n",
            "learners\n",
            "their competencies\n",
            "This\n",
            "we\n",
            "each learner\n",
            "the same learning experience\n",
            "their underlying competencies\n",
            "uniform evaluation mechanisms\n",
            "outcomes\n",
            "This research\n",
            "initial results\n",
            "that direction\n",
            "ACKNOWLEDGEMENTS\n",
            "The authors\n",
            "the con-\n",
            "tributions\n",
            "the project associates\n",
            "Thrivikram Mudunuri\n",
            "Juhi Singh\n",
            "Naman Dosi\n",
            "Kartik Gupta\n",
            "REFERENCES\n",
            "[1] Todd Rose\n",
            "The end\n",
            "a\n",
            "world\n",
            "that\n",
            "sameness\n",
            "Penguin UK\n",
            "[2] L. Todd Rose\n",
            "Parisa Rouhani\n",
            "Kurt W. Fischer\n",
            "The science\n",
            "the individual\n",
            "Mind\n",
            "Brain\n",
            "Education\n",
            "Maureen Tam\n",
            "Outcomes-based approach\n",
            "quality\n",
            "assessment\n",
            "curriculum improvement\n",
            "higher\n",
            "education\n",
            "Quality Assurance\n",
            "Education\n",
            "22(2):158{168\n",
            "Laurie Brady\n",
            "Outcome based education\n",
            "a critique\n",
            "The Curriculum Journal\n",
            "[5] Praseeda\n",
            "Srinath Srinivasa\n",
            "Prasad Ram\n",
            "the myth\n",
            "evidence\n",
            "competency model\n",
            "Gooru Tech Report\n",
            "[6] Stephen E. Fancsali\n",
            "Guoguo Zheng\n",
            "Yanyan Tan\n",
            "Steven Ritter\n",
            "Susan R. Berman\n",
            "April Galyardt\n",
            "embedded formative assessment\n",
            "state\n",
            "summative test scores\n",
            "'\n",
            "[7] Mingyu Feng\n",
            "Neil T. Heffernan\n",
            "Kenneth R.\n",
            "Koedinger\n",
            "state test scores\n",
            "intelligent tutoring systems\n",
            "metrics\n",
            "assistance\n",
            "Springer Berlin\n",
            "Heidelberg\n",
            "[8] Kenneth R. Koedinger\n",
            "Jihee Kim\n",
            "Julianna Zhuxin\n",
            "Jia\n",
            "Elizabeth A. McLaughlin\n",
            "Norman L. Bier\n",
            "Learning\n",
            "a spectator sport\n",
            "a mooc\n",
            "L@S\n",
            "ACM\n",
            "[9] J.D. Fletcher\n",
            "Evidence\n",
            "technology-assisted instruction\n",
            "Technology\n",
            "Applications\n",
            "Education\n",
            "A Learning View\n",
            "pages\n",
            "[10] Corinna Cortes\n",
            "Vladimir Vapnik\n",
            "Support-vector\n",
            "networks\n",
            "Machine Learning\n",
            "The 12th International Conference\n",
            "Educational Data Mining\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Auxiliary Verb(s) – Verb \\\\\n",
        "Auxiliary Verb(s) – Verb – Subject Complement  \\\\\n",
        "Auxiliary Verb(s) – Verb – Direct Object \\\\\n",
        "Auxiliary Verb(s) – Verb – Direct Object – Object Complement \\\\\n",
        "Auxiliary Verb (s) – Verb – Indirect Object – Direct Object \\\\\n",
        "Verb – P-word \\\\\n",
        "Verb – P-word – Direct Object \\\\\n",
        "Verb – Direct Object – P-word \\\\\n",
        "Auxiliary Verb(s) – Verb – P-word \\\\\n",
        "Verb – Prepositional Phrase \\\\\n",
        "Auxiliary Verb(s) – Verb – Prepositional Phrase \\\\\n",
        "Auxiliary Verb(s) – Adverb Phrase – Verb \\\\\n",
        "Auxiliary Verb(s) – Adverb Phrase – Verb – Prepositional Phrase \\\\\n",
        "Auxiliary Verb(s) – Verb – Adverb Phrase \\\\\n",
        "Verb – Verb Phrase \\\\\n",
        "Verb – Verb Phrase – Direct Object \\\\\n",
        "Auxiliary Verb(s) – Verb – Verb Phrase \\\\\n",
        "Auxiliary Verb(s) – Adverb Phrase – Verb – Verb Phrase \\\\\n",
        "Adverb Phrase – Verb – Verb Phrase \\\\\n",
        "Adverb Phrase – Verb – Prepositional Phrase \\\\\n",
        "Determiner – Verb \\\\\n",
        "Determiner – Verb – Adverb Phrase \\\\\n",
        "Determiner – Verb – Prepositional Phrase \\\\\n",
        "Determiner – Adverb Phrase – Verb – Prepositional Phrase \\\\\n",
        "Determiner – Verb – Direct Object \\\\"
      ],
      "metadata": {
        "id": "7euexSuz47sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "nlp = spacy.load('en_core_web_sm') \n",
        "matcher=Matcher(nlp.vocab)\n",
        "fil=open(\"/sample.txt\",'r')\n",
        "\n",
        "text=fil.read()\n",
        "\n",
        "pattern=[{'POS': 'AUX','OP':'?'},\n",
        "         {'POS': 'DET','OP': '?'},\n",
        "         {'POS': 'VERB', 'OP': '?'},\n",
        "         {'POS': 'ADV', 'OP': '*'},\n",
        "         {'OP': '?'}, # additional wildcard - match any text in between\n",
        "         {'POS': 'VERB', 'OP': '+'}]\n",
        "\n",
        "doc=nlp(text)\n",
        "matcher.add(\"my matcher\",[pattern])\n",
        "matches=matcher(doc)"
      ],
      "metadata": {
        "id": "OkNtCUjv2UNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_9PxIWe9r4T",
        "outputId": "18c436f4-bbab-4449-8da4-f3907dc64886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1075"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for match_id,start,end in matches:\n",
        "    print(doc[start:end])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S9Ye00s88Ks",
        "outputId": "1424a730-00a1-47dd-ebd9-1e97d5de772b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating\n",
            "practices based\n",
            "based\n",
            ", imparts\n",
            "imparts\n",
            "by adopting\n",
            "adopting\n",
            "are designed\n",
            "designed\n",
            ", having\n",
            "having\n",
            "have found\n",
            "found\n",
            "models based\n",
            "based\n",
            "This research proposes\n",
            "research proposes\n",
            "proposes\n",
            "for providing\n",
            "providing\n",
            ", refers\n",
            "refers\n",
            "data generated\n",
            "generated\n",
            "are built\n",
            "built\n",
            ", based\n",
            "based\n",
            "are clustered\n",
            "clustered\n",
            "are clustered to observe\n",
            "clustered to observe\n",
            "to observe\n",
            "observe\n",
            "in learning\n",
            "learning\n",
            "also shows\n",
            "shows\n",
            ", validating\n",
            "validating\n",
            "is to create\n",
            "to create\n",
            "create\n",
            "is to create empowered\n",
            "to create empowered\n",
            "create empowered\n",
            "empowered\n",
            ", upholding\n",
            "upholding\n",
            "and possessing\n",
            "possessing\n",
            "to acquire\n",
            "acquire\n",
            "of learning\n",
            "learning\n",
            "learning practices based\n",
            "practices based\n",
            "based\n",
            "has lead\n",
            "lead\n",
            "individuals behave\n",
            "behave\n",
            "behave, learn\n",
            ", learn\n",
            "learn\n",
            "learn, develop\n",
            ", develop\n",
            "develop\n",
            "develop and apply\n",
            "and apply\n",
            "apply\n",
            "to provide\n",
            "provide\n",
            "by addressing\n",
            "addressing\n",
            "have shown\n",
            "shown\n",
            "of finding\n",
            "finding\n",
            "rapidly diminishes\n",
            "diminishes\n",
            "is popularly called\n",
            "popularly called\n",
            "called\n",
            "model based\n",
            "based\n",
            "does not capture\n",
            "not capture\n",
            "capture\n",
            "Each individual has\n",
            "individual has\n",
            "has\n",
            "to learn\n",
            "learn\n",
            "the emerging\n",
            "emerging\n",
            "towards standardizing\n",
            "standardizing\n",
            "is to focus\n",
            "to focus\n",
            "focus\n",
            "focus on learning\n",
            "on learning\n",
            "learning\n",
            "model focuses\n",
            "focuses\n",
            "to produce\n",
            "produce\n",
            ", discounts\n",
            "discounts\n",
            "is also considered\n",
            "also considered\n",
            "considered\n",
            "be strongly rooted\n",
            "strongly rooted\n",
            "rooted\n",
            "we show\n",
            "show\n",
            "data generated\n",
            "generated\n",
            ", referred\n",
            "referred\n",
            "can be used\n",
            "be used\n",
            "used\n",
            "be used to reason\n",
            "used to reason\n",
            "to reason\n",
            "reason\n",
            "the underlying\n",
            "underlying\n",
            "also show\n",
            "show\n",
            "to predict\n",
            "predict\n",
            "be used\n",
            "used\n",
            "we need\n",
            "need\n",
            "need to build\n",
            "to build\n",
            "build\n",
            "hence validating\n",
            "validating\n",
            ", discussed\n",
            "discussed\n",
            "for determining\n",
            "determining\n",
            "have been addressed\n",
            "been addressed\n",
            "addressed\n",
            "been to correlate\n",
            "to correlate\n",
            "correlate\n",
            "of learning\n",
            "learning\n",
            "like watching\n",
            "watching\n",
            "or learning\n",
            "learning\n",
            "learning by doing\n",
            "by doing\n",
            "doing\n",
            "on learning\n",
            "learning\n",
            "don't focus\n",
            "n't focus\n",
            "focus\n",
            "and follow\n",
            "follow\n",
            "to collect\n",
            "collect\n",
            "of learning\n",
            "learning\n",
            "and use\n",
            "use\n",
            "to correlate\n",
            "correlate\n",
            "We focus\n",
            "focus\n",
            "activities involving\n",
            "involving\n",
            "involving learners consuming\n",
            "learners consuming\n",
            "consuming\n",
            "is contrasted\n",
            "contrasted\n",
            "as follows\n",
            "follows\n",
            "outcomes refer\n",
            "refer\n",
            "data collected\n",
            "collected\n",
            "being assessed\n",
            "assessed\n",
            "has explicitly prepared\n",
            "explicitly prepared\n",
            "prepared\n",
            "evidence pertains\n",
            "pertains\n",
            "data collected\n",
            "collected\n",
            "the learner pertaining\n",
            "learner pertaining\n",
            "pertaining\n",
            "\n",
            "Existing\n",
            "Existing\n",
            "of determining\n",
            "determining\n",
            "determining the underlying\n",
            "the underlying\n",
            "underlying\n",
            ", has\n",
            "has\n",
            "There is\n",
            "is\n",
            "that uses\n",
            "uses\n",
            ", based\n",
            "based\n",
            "and maps\n",
            "maps\n",
            "We propose\n",
            "propose\n",
            "that explores\n",
            "explores\n",
            ", generated\n",
            "generated\n",
            "generated while achieving\n",
            "while achieving\n",
            "achieving\n",
            ", collected\n",
            "collected\n",
            "is modeled\n",
            "modeled\n",
            "is modeled to map\n",
            "modeled to map\n",
            "to map\n",
            "map\n",
            "can be considered\n",
            "be considered\n",
            "considered\n",
            "an individual makes\n",
            "individual makes\n",
            "makes\n",
            "which contains\n",
            "contains\n",
            "to gather\n",
            "gather\n",
            "when learning\n",
            "learning\n",
            "when learning happens\n",
            "learning happens\n",
            "happens\n",
            "is continuously captured\n",
            "continuously captured\n",
            "captured\n",
            "can happen\n",
            "happen\n",
            "We want\n",
            "want\n",
            "want to focus\n",
            "to focus\n",
            "focus\n",
            "dont have\n",
            "nt have\n",
            "have\n",
            "have to rely\n",
            "to rely\n",
            "rely\n",
            "to determine\n",
            "determine\n",
            "model based\n",
            "based\n",
            "can also be used\n",
            "also be used\n",
            "be used\n",
            "used\n",
            "be used to identify\n",
            "used to identify\n",
            "to identify\n",
            "identify\n",
            "the outcomes state\n",
            "outcomes state\n",
            "state\n",
            "the individual has\n",
            "individual has\n",
            "has\n",
            "the evidence indicates\n",
            "evidence indicates\n",
            "indicates\n",
            "can only analyze\n",
            "only analyze\n",
            "analyze\n",
            "and address\n",
            "address\n",
            "The model based\n",
            "model based\n",
            "based\n",
            ", acts\n",
            "acts\n",
            "of aiding\n",
            "aiding\n",
            "and evaluating\n",
            "evaluating\n",
            "can also help\n",
            "also help\n",
            "help\n",
            "the students identify\n",
            "students identify\n",
            "identify\n",
            "and help\n",
            "help\n",
            "help them acquire\n",
            "them acquire\n",
            "acquire\n",
            "to learn\n",
            "learn\n",
            "would improve\n",
            "improve\n",
            "may not have\n",
            "not have\n",
            "have\n",
            "may not have standardized\n",
            "not have standardized\n",
            "have standardized\n",
            "standardized\n",
            "to aid\n",
            "aid\n",
            "models based\n",
            "based\n",
            "would help\n",
            "help\n",
            "would help to map\n",
            "help to map\n",
            "to map\n",
            "map\n",
            "is to create\n",
            "to create\n",
            "create\n",
            "for collecting\n",
            "collecting\n",
            "to argue\n",
            "argue\n",
            "may happen\n",
            "happen\n",
            "may require\n",
            "require\n",
            "to reason\n",
            "reason\n",
            "to address\n",
            "address\n",
            "we adopt\n",
            "adopt\n",
            "and treat\n",
            "treat\n",
            "evidences collected\n",
            "collected\n",
            "are then given\n",
            "then given\n",
            "given\n",
            "a machine learning\n",
            "machine learning\n",
            "learning\n",
            "to find\n",
            "find\n",
            "the outcomes based\n",
            "outcomes based\n",
            "based\n",
            "data used\n",
            "used\n",
            "used to build\n",
            "to build\n",
            "build\n",
            "is collected\n",
            "collected\n",
            ", implemented\n",
            "implemented\n",
            "has aggregated\n",
            "aggregated\n",
            ", provided\n",
            "provided\n",
            "The learning\n",
            "learning\n",
            "any content used\n",
            "content used\n",
            "used\n",
            "used to obtain\n",
            "to obtain\n",
            "obtain\n",
            "Learners enroll\n",
            "enroll\n",
            "is organized\n",
            "organized\n",
            "is seen\n",
            "seen\n",
            "of learning\n",
            "learning\n",
            "may have\n",
            "have\n",
            "resources mapped\n",
            "mapped\n",
            "Students consume\n",
            "consume\n",
            "Students consume learning\n",
            "consume learning\n",
            "learning\n",
            ", give\n",
            "give\n",
            "to earn\n",
            "earn\n",
            "Instructors evaluate\n",
            "evaluate\n",
            "and provide\n",
            "provide\n",
            "The scores indicate\n",
            "scores indicate\n",
            "indicate\n",
            "are mapped\n",
            "mapped\n",
            "also has\n",
            "has\n",
            "the learner has\n",
            "learner has\n",
            "has\n",
            "has to take\n",
            "to take\n",
            "take\n",
            "to earn\n",
            "earn\n",
            "data collected\n",
            "collected\n",
            "is divided\n",
            "divided\n",
            "are resources used\n",
            "resources used\n",
            "used\n",
            "assessments act\n",
            "act\n",
            "of learning\n",
            "learning\n",
            "is said\n",
            "said\n",
            "have achieved\n",
            "achieved\n",
            "`completed\n",
            "completed\n",
            "one gets\n",
            "gets\n",
            "does not award\n",
            "not award\n",
            "award\n",
            "`fail\n",
            "fail\n",
            "The learner keeps\n",
            "learner keeps\n",
            "keeps\n",
            "The learner keeps attempting\n",
            "learner keeps attempting\n",
            "keeps attempting\n",
            "attempting\n",
            "the learner gets\n",
            "learner gets\n",
            "gets\n",
            "is then set\n",
            "then set\n",
            "set\n",
            "`completed\n",
            "completed\n",
            "is marked\n",
            "marked\n",
            "The data used\n",
            "data used\n",
            "used\n",
            "used to build\n",
            "to build\n",
            "build\n",
            "build Evidence based\n",
            "Evidence based\n",
            "based\n",
            "model contains\n",
            "contains\n",
            "have completed\n",
            "completed\n",
            "a learner consumes\n",
            "learner consumes\n",
            "consumes\n",
            "to learn\n",
            "learn\n",
            "is logged\n",
            "logged\n",
            "event(started consuming\n",
            "consuming\n",
            "is repeated\n",
            "repeated\n",
            "finishes consuming\n",
            "consuming\n",
            "are captured\n",
            "captured\n",
            "Individuals consume\n",
            "consume\n",
            "resources mapped\n",
            "mapped\n",
            "the end give\n",
            "end give\n",
            "give\n",
            "to get\n",
            "get\n",
            " \n",
            "\n",
            "Using\n",
            "Using\n",
            "have built\n",
            "built\n",
            "to determine\n",
            "determine\n",
            "the competency based\n",
            "competency based\n",
            "based\n",
            "We built\n",
            "built\n",
            "to test\n",
            "test\n",
            "is as follows\n",
            "as follows\n",
            "follows\n",
            "The time spent\n",
            "time spent\n",
            "spent\n",
            "spent on learning\n",
            "on learning\n",
            "learning\n",
            "resources consumed\n",
            "consumed\n",
            "can predict\n",
            "predict\n",
            "the underlying\n",
            "underlying\n",
            "The features identified\n",
            "features identified\n",
            "identified\n",
            "time spent\n",
            "spent\n",
            "time spent\n",
            "spent\n",
            "resources used\n",
            "used\n",
            "used for acquiring\n",
            "for acquiring\n",
            "acquiring\n",
            "were given\n",
            "given\n",
            "were given a completed\n",
            "given a completed\n",
            "a completed\n",
            "completed\n",
            "status based\n",
            "based\n",
            "That serves\n",
            "serves\n",
            "The dataset has\n",
            "dataset has\n",
            "has\n",
            ") pairs\n",
            "pairs\n",
            "was divided\n",
            "divided\n",
            "and testing\n",
            "testing\n",
            "We built\n",
            "built\n",
            "We classified\n",
            "classified\n",
            "the data using\n",
            "data using\n",
            "using\n",
            "was found\n",
            "found\n",
            "to classify\n",
            "classify\n",
            "as shown\n",
            "shown\n",
            "metrics comparing\n",
            "comparing\n",
            "model using\n",
            "using\n",
            "function states\n",
            "states\n",
            "states that using\n",
            "that using\n",
            "using\n",
            "time spent\n",
            "spent\n",
            "time spent\n",
            "spent\n",
            "can significantly predict\n",
            "significantly predict\n",
            "predict\n",
            "the underlying\n",
            "underlying\n",
            "are determined\n",
            "determined\n",
            "was not used\n",
            "not used\n",
            "used\n",
            "to build\n",
            "build\n",
            "This shows\n",
            "shows\n",
            "can be used\n",
            "be used\n",
            "used\n",
            "to model\n",
            "model\n",
            "the underlying\n",
            "underlying\n",
            "was made\n",
            "made\n",
            "was made to classify\n",
            "made to classify\n",
            "to classify\n",
            "classify\n",
            "model varied\n",
            "varied\n",
            "model computed\n",
            "computed\n",
            "in determining\n",
            "determining\n",
            "This indicates\n",
            "indicates\n",
            "cannot use\n",
            "not use\n",
            "use\n",
            "There is\n",
            "is\n",
            "to build\n",
            "build\n",
            "to understand\n",
            "understand\n",
            "better and improve\n",
            "and improve\n",
            "improve\n",
            "must consider\n",
            "consider\n",
            "we need\n",
            "need\n",
            "need to build\n",
            "to build\n",
            "build\n",
            "and aggregate\n",
            "aggregate\n",
            "the models based\n",
            "models based\n",
            "based\n",
            "To do\n",
            "do\n",
            "we require\n",
            "require\n",
            "instead of aggregating\n",
            "of aggregating\n",
            "aggregating\n",
            "aggregating time spent\n",
            "time spent\n",
            "spent\n",
            "we looked\n",
            "looked\n",
            "time spent\n",
            "spent\n",
            "and aggregated\n",
            "aggregated\n",
            "we used\n",
            "used\n",
            "and modeled\n",
            "modeled\n",
            "the time spent\n",
            "time spent\n",
            "spent\n",
            "each resource mapped\n",
            "resource mapped\n",
            "mapped\n",
            ". Using\n",
            "Using\n",
            "we computed\n",
            "computed\n",
            "the time spent\n",
            "time spent\n",
            "spent\n",
            "also observed\n",
            "observed\n",
            "some individuals consumed\n",
            "individuals consumed\n",
            "consumed\n",
            "again. Based\n",
            ". Based\n",
            "Based\n",
            "we formed\n",
            "formed\n",
            "There is\n",
            "is\n",
            "models built\n",
            "built\n",
            "each learner based\n",
            "learner based\n",
            "based\n",
            "We wanted\n",
            "wanted\n",
            "wanted to observe\n",
            "to observe\n",
            "observe\n",
            "the time spent\n",
            "time spent\n",
            "spent\n",
            "could predict\n",
            "predict\n",
            "also wanted\n",
            "wanted\n",
            "wanted to observe\n",
            "to observe\n",
            "observe\n",
            "the models built\n",
            "models built\n",
            "built\n",
            "learner had\n",
            "had\n",
            "could be merged\n",
            "be merged\n",
            "merged\n",
            "there is\n",
            "is\n",
            "time spent\n",
            "spent\n",
            "is stored\n",
            "stored\n",
            "the vector tells\n",
            "vector tells\n",
            "tells\n",
            "were consumed\n",
            "consumed\n",
            "the vector varied\n",
            "vector varied\n",
            "varied\n",
            "To build\n",
            "build\n",
            "and compare\n",
            "compare\n",
            "we require\n",
            "require\n",
            "To achieve\n",
            "achieve\n",
            "we transformed\n",
            "transformed\n",
            "the time spent\n",
            "time spent\n",
            "spent\n",
            "the following\n",
            "following\n",
            "We computed\n",
            "computed\n",
            "time spent\n",
            "spent\n",
            "This value varied\n",
            "value varied\n",
            "varied\n",
            "After observing\n",
            "observing\n",
            "we decided\n",
            "decided\n",
            "decided to have\n",
            "to have\n",
            "have\n",
            "and computed\n",
            "computed\n",
            "resources consumed\n",
            "consumed\n",
            "We populated\n",
            "populated\n",
            "We arrived\n",
            "arrived\n",
            "by dividing\n",
            "dividing\n",
            "has consumed\n",
            "consumed\n",
            ", spending\n",
            "spending\n",
            "will have\n",
            "have\n",
            "will have\n",
            "have\n",
            "has not finished\n",
            "not finished\n",
            "finished\n",
            "has not finished consuming\n",
            "not finished consuming\n",
            "finished consuming\n",
            "consuming\n",
            ") has\n",
            "has\n",
            "will have\n",
            "have\n",
            "2 indicating\n",
            "indicating\n",
            "the user consumed\n",
            "user consumed\n",
            "consumed\n",
            ", shows\n",
            "shows\n",
            "the data passed\n",
            "data passed\n",
            "passed\n",
            "code refers\n",
            "refers\n",
            "The row containing\n",
            "row containing\n",
            "containing\n",
            ", shows\n",
            "shows\n",
            "example mentioned\n",
            "mentioned\n",
            "also includes\n",
            "includes\n",
            "also includes normalized\n",
            "includes normalized\n",
            "normalized\n",
            "normalized total_time spent\n",
            "total_time spent\n",
            "spent\n",
            "and normalized\n",
            "normalized\n",
            "normalized average_time spent\n",
            "average_time spent\n",
            "spent\n",
            "\n",
            "\n",
            "Figure\n",
            "Figure\n",
            "Data passed\n",
            "passed\n",
            "was used\n",
            "used\n",
            "was used to classify\n",
            "used to classify\n",
            "to classify\n",
            "classify\n",
            "who had\n",
            "had\n",
            "(completed\n",
            "completed\n",
            "were selected\n",
            "selected\n",
            "There were\n",
            "were\n",
            "who satisfied\n",
            "satisfied\n",
            "were built\n",
            "built\n",
            "was divided\n",
            "divided\n",
            "each learner gave\n",
            "learner gave\n",
            "gave\n",
            "was calculated\n",
            "calculated\n",
            "matrix generated\n",
            "generated\n",
            "model according\n",
            "according\n",
            "the formula mentioned\n",
            "formula mentioned\n",
            "mentioned\n",
            "Each model generated\n",
            "model generated\n",
            "generated\n",
            "also built\n",
            "built\n",
            "model comprising\n",
            "comprising\n",
            "and called\n",
            "called\n",
            "as detailed\n",
            "detailed\n",
            "models populated\n",
            "populated\n",
            "populated were clustered\n",
            "were clustered\n",
            "clustered\n",
            "populated were clustered using\n",
            "were clustered using\n",
            "clustered using\n",
            "using\n",
            "neighbor clustering\n",
            "clustering\n",
            "to observe\n",
            "observe\n",
            "was used\n",
            "used\n",
            "to cluster\n",
            "cluster\n",
            "To find\n",
            "find\n",
            "was used\n",
            "used\n",
            "was used to find\n",
            "used to find\n",
            "to find\n",
            "find\n",
            "was computed\n",
            "computed\n",
            "was computed and plotted\n",
            "computed and plotted\n",
            "and plotted\n",
            "plotted\n",
            "2 shows\n",
            "shows\n",
            "the squared\n",
            "squared\n",
            "method showing\n",
            "showing\n",
            "\n",
            "\n",
            "Using\n",
            "Using\n",
            "we found\n",
            "found\n",
            "This says\n",
            "says\n",
            "models including\n",
            "including\n",
            "can be clustered\n",
            "be clustered\n",
            "clustered\n",
            "there are\n",
            "are\n",
            "Fig.3 shows\n",
            "shows\n",
            "models including\n",
            "including\n",
            "point refers\n",
            "refers\n",
            "point indicates\n",
            "indicates\n",
            "We see\n",
            "see\n",
            "don't cluster\n",
            "n't cluster\n",
            "cluster\n",
            "does not represent\n",
            "not represent\n",
            "represent\n",
            "This validates\n",
            "validates\n",
            "there is\n",
            "is\n",
            "models built\n",
            "built\n",
            "each learner based\n",
            "learner based\n",
            "based\n",
            "hence validates\n",
            "validates\n",
            "also shows\n",
            "shows\n",
            "need not build\n",
            "not build\n",
            "build\n",
            "would make\n",
            "make\n",
            "to map\n",
            "map\n",
            "We find\n",
            "find\n",
            "there are\n",
            "are\n",
            "can be used\n",
            "be used\n",
            "used\n",
            "be used to find\n",
            "used to find\n",
            "to find\n",
            "find\n",
            "We need\n",
            "need\n",
            "need to determine\n",
            "to determine\n",
            "determine\n",
            "and provide\n",
            "provide\n",
            "We proposed\n",
            "proposed\n",
            "that uses\n",
            "uses\n",
            "uses data generated\n",
            "data generated\n",
            "generated\n",
            "to find\n",
            "find\n",
            "The experiments shows\n",
            "experiments shows\n",
            "shows\n",
            "shows that having\n",
            "that having\n",
            "having\n",
            "can be tuned\n",
            "be tuned\n",
            "tuned\n",
            "be tuned to get\n",
            "tuned to get\n",
            "to get\n",
            "get\n",
            "does not represent\n",
            "not represent\n",
            "represent\n",
            "This presses\n",
            "presses\n",
            "to consider\n",
            "consider\n",
            "not rely\n",
            "rely\n",
            "to map\n",
            "map\n",
            "also says\n",
            "says\n",
            "cannot provide\n",
            "not provide\n",
            "provide\n",
            "cannot validate\n",
            "not validate\n",
            "validate\n",
            "validate their underlying\n",
            "their underlying\n",
            "underlying\n",
            "This research shows\n",
            "research shows\n",
            "shows\n",
            "would like\n",
            "like\n",
            "would like to acknowledge\n",
            "like to acknowledge\n",
            "to acknowledge\n",
            "acknowledge\n",
            "acknowledge and thank\n",
            "and thank\n",
            "thank\n",
            "to succeed\n",
            "succeed\n",
            "that values\n",
            "values\n",
            "-based\n",
            "based\n",
            "Outcome based\n",
            "based\n",
            "\n",
            "Validating\n",
            "Validating\n",
            "evidence based\n",
            "based\n",
            "\n",
            "Using\n",
            "Using\n",
            "\n",
            "Using embedded\n",
            "Using embedded\n",
            "embedded\n",
            "to predict\n",
            "predict\n",
            ". Predicting\n",
            "Predicting\n",
            ": Developing\n",
            "Developing\n",
            "\n",
            "measure\n",
            "measure\n",
            "measure assistance required\n",
            "assistance required\n",
            "required\n",
            ": Doing\n",
            "Doing\n",
            "\n",
            "watching\n",
            "watching\n",
            "watching for learning\n",
            "for learning\n",
            "learning\n",
            "for learning\n",
            "learning\n",
            "-assisted\n",
            "assisted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yake\n",
        "kw_extractor = yake.KeywordExtractor()\n",
        "\n",
        "language = \"en\"\n",
        "max_ngram_size = 5\n",
        "deduplication_threshold = 0.9\n",
        "numOfKeywords = 100\n",
        "custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)\n",
        "keywords = custom_kw_extractor.extract_keywords(text)\n",
        "for kw in keywords:\n",
        "    print(kw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwxR1AFDBEQP",
        "outputId": "e79059b7-cae5-4039-dcd8-d4577eee9041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Myth of the Average', -255.52018554277043)\n",
            "('learner in the next experiment', -185.28091954265852)\n",
            "('learning happens in a Technology', -156.52475358570123)\n",
            "('outcome of the competency', -20.98116445943632)\n",
            "('data for each individual', -13.078651270387619)\n",
            "('resources and the time', -10.255543462667205)\n",
            "('outcome of a competency', -8.265355452831852)\n",
            "('individual during the learning', -7.343396680639096)\n",
            "('individual who is average', -3.0442403774854525)\n",
            "('individual has the competency', -2.692462934123689)\n",
            "('based on the evidences', -2.4243647423675934)\n",
            "('competency of an individual', -2.39424263592857)\n",
            "('competency for that individual', -2.377597514317851)\n",
            "('data of the learners', -2.318695008341634)\n",
            "('data for each learner', -2.14781415498711)\n",
            "('model for each individual', -2.1084161232547594)\n",
            "('resources for a competency', -2.0784479045777173)\n",
            "('resources at a competency', -2.042418479473433)\n",
            "('competency while the evidence', -1.618308381295971)\n",
            "('based on the learner', -1.6152344721259742)\n",
            "('outcome of the corresponding competency', -1.4598156459465437)\n",
            "('model on all individuals', -1.4429842139759341)\n",
            "('evidences for that competency', -1.3554560150522559)\n",
            "('competency of the learner', -1.1397040699056613)\n",
            "('learners to their competency', -1.0062190510811466)\n",
            "('competency of a learner', -0.9443562485698435)\n",
            "('based on their learning', -0.9278814605954983)\n",
            "('learner the same learning', -0.9073854546392855)\n",
            "('models that uses evidences', -0.8791253143782842)\n",
            "('resources used during the learning', -0.8407691096197175)\n",
            "('models for each learner', -0.7513608291070202)\n",
            "('model for all learners', -0.6596531398364732)\n",
            "('competency may have several learning', -0.5852834567286951)\n",
            "('Evidence Based Competency Model', 0.000925882190462692)\n",
            "('Based Competency Model', 0.0031477731082638297)\n",
            "('Evidence Based Competency', 0.004156182715386293)\n",
            "('build Evidence based competency model', 0.004470408844417688)\n",
            "('model', 0.00464985749148498)\n",
            "('learner', 0.005073499089737829)\n",
            "('learning', 0.005364276551913944)\n",
            "('Competency', 0.005487520064099748)\n",
            "('average model', 0.006055299226941405)\n",
            "('models', 0.00644980232689852)\n",
            "('average learner model', 0.006637649348631752)\n",
            "('proposes Evidence Based Competency Model', 0.007236191714420929)\n",
            "('individual learner', 0.007336575432417043)\n",
            "('individual learner models', 0.008009582527581403)\n",
            "('Competency Model', 0.008454246559634162)\n",
            "('data', 0.008802338302168585)\n",
            "('learners', 0.009301414997852687)\n",
            "('individual', 0.009568313814642139)\n",
            "('Average', 0.009573276924592283)\n",
            "('Individual models', 0.010868720455319536)\n",
            "('learners models and average model', 0.010977661487210202)\n",
            "('time', 0.011108754270952445)\n",
            "('resources', 0.011616119275860808)\n",
            "('based', 0.0121268883634175)\n",
            "('time spent', 0.012279654851809903)\n",
            "('Evidence', 0.013536048229200574)\n",
            "('SVM model', 0.013933543566924386)\n",
            "('based competency model contains learners', 0.014231377795495005)\n",
            "('Based Competency', 0.014441590743291863)\n",
            "('build individual learner models', 0.014478279347343364)\n",
            "('learning resources', 0.014717438329700154)\n",
            "('average learner model computed', 0.014742962647280639)\n",
            "('competency model based on evidences', 0.015084186484302731)\n",
            "('Evidence Based', 0.015455394002054717)\n",
            "('competency model based', 0.01573886554131915)\n",
            "('individual learners models and average', 0.01659490402424562)\n",
            "('models including the average model', 0.01663527554666367)\n",
            "('build Evidence based competency', 0.019091193712367928)\n",
            "('learning process', 0.01922846939818653)\n",
            "('models based', 0.019687263733335274)\n",
            "('Evidences', 0.019783455104216224)\n",
            "('average SVM model', 0.020218039626930813)\n",
            "('activity data', 0.02027242127066993)\n",
            "('resource', 0.020743070135465728)\n",
            "('average through evidence based competency', 0.021125371619604944)\n",
            "('single average model', 0.022446359389069446)\n",
            "('learner model', 0.023359777614264377)\n",
            "('individual SVM models', 0.024504882438962008)\n",
            "('learning activity data', 0.02507469534720783)\n",
            "('Individual learner data', 0.02512673542688774)\n",
            "('individual models built', 0.025905587007521144)\n",
            "('build individual models', 0.02734703022977539)\n",
            "('outcomes', 0.027755864256681553)\n",
            "('average time spent', 0.02799454549453947)\n",
            "('average SVM model varied', 0.028674954430334455)\n",
            "('proposes Evidence Based Competency', 0.029999959820601548)\n",
            "('average learner', 0.03061723753677639)\n",
            "('model based on evidences', 0.030889977577171553)\n",
            "('spent', 0.03111547156274672)\n",
            "('average time', 0.03142032376245001)\n",
            "('assessments', 0.031775581686902345)\n",
            "('learner based', 0.033199146961836276)\n",
            "('Outcome Based Education', 0.033764869090671834)\n",
            "('model based on statistical averages', 0.03462262090600642)\n",
            "('number', 0.035557562326244796)\n",
            "('models based on group averages', 0.03840178113289823)\n",
            "('underlying competency', 0.03922287269142383)\n"
          ]
        }
      ]
    }
  ]
}